{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install synapseclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install synapseutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import synapseclient \n",
    "#  import synapseutils \n",
    " \n",
    "#  syn = synapseclient.Synapse() \n",
    "#  syn.login('finamintoastcrunch','1Hjldria!') \n",
    "#  files = synapseutils.syncFromSynapse(syn, ' syn2825306 ') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "qTo_HuQkGgAq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_visualizer import visualizer \n",
    "\n",
    "from tensorflow.keras.layers import*\n",
    "import shap\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow.keras.backend as K\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Conv1D\n",
    "# from keras.layers import Conv1DTranspose\n",
    "# from keras.layers import Flatten, Reshape\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import losses\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARENTS = 7\n",
    "NUM_TARGETS = 372\n",
    "NUM_TIME_STEPS = 11\n",
    "NUM_REPLICATES_TOTAL = 4\n",
    "NUM_REPLICATES = 3 #used to be 4, but replicate 4 is trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "gXpISOijEYqQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# matrix_path = \"regulator-gene-matrix.csv\"\n",
    "# data_path_syn = r\"C:\\Users\\Fin Amin\\Desktop\\StemCellResearch\\Fin_preProcessed\\synData\"\n",
    "# data_path_inter =  r\"C:\\Users\\Fin Amin\\Desktop\\StemCellResearch\\Fin_preProcessed\\interpolatedOnly\"\n",
    "# data_path_og_exp1 = r\"C:\\Users\\Fin Amin\\Desktop\\StemCellResearch\\Fin_preProcessed\\datasets\\exp1\"\n",
    "# data_path_testSet = r\"C:\\Users\\Fin Amin\\Desktop\\StemCellResearch\\testSetFixed\"\n",
    "# data_path_petal = r\"C:\\Users\\Fin Amin\\Desktop\\StemCellResearch\\petal_len.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_RGM = r'Regulations_Control_Altona.csv'\n",
    "dirty_regulations = r'FullTable_Control.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372, 44)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirtyRGM = pd.read_csv(dirty_RGM,  index_col = 0, )#on_bad_lines='skip')\n",
    "dirtyReg = pd.read_csv(dirty_regulations,  index_col = 0,)# on_bad_lines='skip')\n",
    "dirtyReg = dirtyReg.select_dtypes(include=np.number)\n",
    "dirtyReg = dirtyReg.to_numpy()\n",
    "dirtyReg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 11, 372)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Fix this. it puts nans where it should not. \n",
    "\n",
    "def fix_dataset(dirtyR):\n",
    "    dataset = np.zeros(shape=(NUM_REPLICATES_TOTAL,NUM_TARGETS, NUM_TIME_STEPS))\n",
    "    ret = np.zeros(shape=(NUM_REPLICATES_TOTAL,NUM_TIME_STEPS, NUM_TARGETS))\n",
    "\n",
    "    for i in range(0,NUM_REPLICATES_TOTAL*NUM_TIME_STEPS, 4):\n",
    "        for j in range(0, NUM_REPLICATES_TOTAL):\n",
    "            dataset[j][:,i//NUM_REPLICATES_TOTAL] = dirtyR[:,(i+j)]\n",
    "    \n",
    "    dataset[dataset==0] = np.nan\n",
    "\n",
    "\n",
    "    for i in range(NUM_REPLICATES_TOTAL):\n",
    "        regScaled = MinMaxScaler().fit_transform(dataset[i].flatten().reshape((-1,1)))\n",
    "        regScaled = regScaled.reshape((NUM_TARGETS, NUM_TIME_STEPS))\n",
    "        regScaled = np.nan_to_num(regScaled, nan= -1.0)\n",
    "        ret[i] = regScaled.T\n",
    "    return ret\n",
    "\n",
    "dataset = fix_dataset(dirtyR=dirtyReg)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 11, 372) (1, 11, 372) (3, 11, 372)\n"
     ]
    }
   ],
   "source": [
    "beanIntensities = dataset[0:2]\n",
    "validation = np.array([dataset[2]])\n",
    "allData = dataset[0:NUM_REPLICATES]\n",
    "print(beanIntensities.shape, validation.shape, allData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the third replicate is trash. we will not use it. \n",
    "# df(dataset[3]).head(11) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372, 372)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulator_gene_matrix = np.load(\"soyBeanRGM.npy\")\n",
    "regulator_gene_matrix = regulator_gene_matrix.astype('float32')\n",
    "regulator_gene_matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Parent Matrix + Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of parent index (7,)\n"
     ]
    }
   ],
   "source": [
    "superParent = regulator_gene_matrix.copy() #init the super parent with the ordinary RGM, and do forward passes with super parent\n",
    "#print(superParent.shape)\n",
    "\n",
    "ones = np.ones((NUM_TARGETS))\n",
    "parentIndex = []\n",
    "not_parentIndex = []\n",
    "for i in range(len(regulator_gene_matrix)):\n",
    "    if (np.isin(regulator_gene_matrix[i], [1])).any():\n",
    "        #print(i)\n",
    "        superParent[i] = ones \n",
    "        parentIndex.append(i)\n",
    "    else:\n",
    "        not_parentIndex.append(i)\n",
    "\n",
    "parentIndex = np.array(parentIndex)\n",
    "parentIndex = tf.convert_to_tensor(parentIndex)\n",
    "parent_idx = parentIndex.numpy()\n",
    "not_parentIndex = np.array(not_parentIndex)\n",
    "not_parentIndex = tf.convert_to_tensor(not_parentIndex)\n",
    "print(\"shape of parent index\", parentIndex.shape)\n",
    "\n",
    "def ignore_noParent_MSE_old(y_true, y_pred): \n",
    "    l = tf.keras.losses.MeanSquaredError()\n",
    "    y_true_pruned = tf.gather(y_true,parentIndex, axis =2) \n",
    "    #print(y_true_pruned.shape\n",
    "    y_pred_pruned = tf.gather(y_pred, parentIndex, axis =2)   \n",
    "    return l(y_true_pruned, y_pred_pruned)\n",
    "\n",
    "#this will not work if the entire dataset is -1 (degenerate), or has only one actual value (also degen)\n",
    "def ignore_noParent_MSE(y_true, y_pred): \n",
    "    l = tf.keras.losses.MeanSquaredError()\n",
    "   # print(y_true.shape) #(None, 44, 372)\n",
    "\n",
    "    #get the parents and flatten them\n",
    "    y_true_pruned = tf.gather(y_true, parentIndex, axis = 2) #axis 2 because batch, time, gene\n",
    "    y_true_pruned = tf.reshape(y_true_pruned, shape=([tf.size(y_true_pruned)] ) )\n",
    "\n",
    "   # print(y_true_pruned.shape)\n",
    "   # print(\"tf size\", tf.size(y_true_pruned))\n",
    "\n",
    "    y_pred_pruned = tf.gather(y_pred, parentIndex, axis = 2) \n",
    "    y_pred_pruned = tf.reshape(y_pred_pruned, shape=([tf.size(y_pred_pruned)]) )\n",
    "\n",
    "    #get the index of the parents which are not -1\n",
    "    y_true_posID = tf.where(y_true_pruned >= 0) #gets args\n",
    "    y_true_posID = tf.squeeze(y_true_posID)\n",
    "    #get the idx of all the -1s \n",
    "    y_true_negID = tf.where(y_true_pruned < 0) \n",
    "    y_true_negID = tf.squeeze(y_true_negID)\n",
    "\n",
    "    #get all the -1s in the parents \n",
    "    y_true_neg = tf.gather(y_true_pruned, y_true_negID) #get all the -1s in y_true\n",
    "    y_pred_neg = tf.gather(y_pred_pruned, y_true_negID) #get the corresponding values for y_pred\n",
    "\n",
    "    #get the indexes where pred should be -1 but is not. get the corresponding index for ytrue\n",
    "    y_shouldBeNegButIsntID = tf.where(y_pred_neg >= 0)  \n",
    "    y_shouldBeNegButIsntID = tf.squeeze(y_shouldBeNegButIsntID) #get the idx which should be -1 for prediction but are not\n",
    "    y_true_wrong = tf.gather(y_true_pruned, y_shouldBeNegButIsntID) #get the same corresponding values from ytrue\n",
    "    y_shouldBeNegButIsnt = tf.gather(y_pred_pruned, y_shouldBeNegButIsntID) #this has all the wrongly predicted values which should be -1 but are not\n",
    "\n",
    "    y_true_pos = tf.gather(y_true_pruned, y_true_posID)\n",
    "    y_pred_pos = tf.gather(y_pred_pruned, y_true_posID)\n",
    "\n",
    "    if tf.size(y_shouldBeNegButIsnt) == 0: #we can not concatenate if the size is 0. \n",
    "        return l(y_true_pos, y_pred_pos)\n",
    "\n",
    "    if tf.size(y_shouldBeNegButIsnt) == 1: #dim goes away if size = 1. \n",
    "        y_shouldBeNegButIsnt = tf.expand_dims(y_shouldBeNegButIsnt, axis = 0) #should all be flattened\n",
    "        y_true_wrong = tf.expand_dims(y_true_wrong, axis=0)\n",
    "\n",
    "    #print(\"y_pred\", (y_pred_pos), \"y_true\", (y_shouldBeNegButIsnt))\n",
    "    try:\n",
    "        y_pred_total = tf.concat([y_pred_pos, y_shouldBeNegButIsnt], axis = 0) #concatenate for total mse\n",
    "        y_true_total = tf.concat([y_true_pos, y_true_wrong], axis = 0)\n",
    "    except Exception as e:\n",
    "        print(y_pred_pos.shape, y_shouldBeNegButIsnt.shape, tf.size(y_shouldBeNegButIsnt))\n",
    "        return l(y_true_pos, y_pred_pos)\n",
    "\n",
    "    return l(y_true_total, y_pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117, 131, 164, 225, 259, 334, 350])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(superParent, cmap='hot');\n",
    "plt.xlabel(\"Substrate\");\n",
    "plt.ylabel(\"Regulator\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(regulator_gene_matrix, cmap='hot');\n",
    "plt.xlabel(\"Substrate\");\n",
    "plt.ylabel(\"Regulator\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1yhzyikoFncq"
   },
   "outputs": [],
   "source": [
    "class EncoderLinear(tf.keras.layers.Layer):\n",
    "    def __init__(self, rgm, input_dim=32, units=32):\n",
    "        super(EncoderLinear, self).__init__()\n",
    "        self.rgm = rgm\n",
    "        \n",
    "        def init_weights(shape, dtype=\"float32\"):\n",
    "\n",
    "            w_init = tf.random_normal_initializer()(shape=shape, dtype=dtype) * tf.convert_to_tensor(self.rgm, dtype=dtype)\n",
    "\n",
    "            return w_init\n",
    "        \n",
    "\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=init_weights(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        return tf.matmul(X, tf.multiply(self.rgm, self.w))\n",
    "    #tf.matmul(inputs, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "4uchxU-bmBDe"
   },
   "outputs": [],
   "source": [
    "class DecoderLinear(tf.keras.layers.Layer):\n",
    "    def __init__(self, rgm, input_dim=32, units=32):\n",
    "        super(DecoderLinear, self).__init__()\n",
    "        self.rgm = rgm\n",
    "\n",
    "        def init_weights(shape, dtype=\"float32\"):\n",
    "\n",
    "            w_init = tf.random_normal_initializer()(shape=shape, dtype=dtype) * tf.transpose(tf.convert_to_tensor(self.rgm, dtype=dtype))\n",
    "\n",
    "            return w_init\n",
    "    \n",
    "        \n",
    "        self.w = tf.Variable(\n",
    "            initial_value=init_weights(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        #return tf.matmul(X, tf.multiply((self.rgm), self.w))\n",
    "        X = tf.matmul(X, tf.multiply(tf.transpose(self.rgm), self.w)) \n",
    "        #return tf.matmul(inputs, self.w)\n",
    "        # v = tf.zeros_like(X)\n",
    "        # u = tf.ones_like(X)\n",
    "        # u = tf.math.scalar_mul(-3.0, u)\n",
    "        \n",
    "        return X#tf.where(tf.math.less(X, v), u, X) #where X is less than 0, return -1 \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "PQVz4BCpmNMd"
   },
   "outputs": [],
   "source": [
    "def encoder(parent_child_biological_association, num_hidden_units=21):\n",
    "    '''\n",
    "    Encoder structure\n",
    "    '''\n",
    "    '''\n",
    "    The data is time-series. Therefore, CNN to learn the temporal relationship between \n",
    "    the intensities for each gene.\n",
    "    '''\n",
    "    en_conv = Conv1D(490, 3, activation = \"relu\")(parent_child_biological_association) # 6*NUM_TARGETS Conv1D(32, 3, activation = \"relu\")(parent_child_biological_association)\n",
    "    en_dense = Flatten()(en_conv)\n",
    "    phenotype = Dense(num_hidden_units)(en_dense)\n",
    "    return phenotype\n",
    "\n",
    "def decoder(X, num_protein_gene, time_steps):\n",
    "    '''\n",
    "    Decoder structure\n",
    "    '''\n",
    "    de_dense = Dense(1024)(X)#Dense(128)(X)\n",
    "    de_dense = Reshape((1, 1024))(de_dense) #tf.reshape(de_dense, (self.batch_size,1,128))\n",
    "    de_deconv = Conv1DTranspose(num_protein_gene, time_steps, activation = \"relu\")(de_dense) #used to be transpose\n",
    "    #de_deconv = Conv1D(num_protein_gene, time_steps, activation = \"relu\")(de_dense) \n",
    "    # gene_reconstruction = self.decoder_biological_operation(de_deconv)\n",
    "    return de_deconv\n",
    "\n",
    "def model(rgm, num_protein_gene, time_steps, num_kinase_regulators, num_hidden_units = 32):\n",
    "    inp = Input(shape=(time_steps, num_kinase_regulators))\n",
    "    x = EncoderLinear(rgm, NUM_TARGETS, NUM_TARGETS)(inp)\n",
    "    enc = encoder(x, num_hidden_units)\n",
    "    dec = decoder(enc, num_protein_gene, time_steps)\n",
    "    out = DecoderLinear(rgm, NUM_TARGETS, NUM_TARGETS)(dec)\n",
    "\n",
    "    _model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinaryAE = model(regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS)\n",
    "ordinaryAE.compile(optimizer='adam', loss=ignore_noParent_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2166 - val_loss: 0.2558\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2039 - val_loss: 0.2488\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2042 - val_loss: 0.2301\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1985 - val_loss: 0.1958\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1687 - val_loss: 0.1413\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1267 - val_loss: 0.0816\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0826 - val_loss: 0.0752\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0841 - val_loss: 0.0649\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0739 - val_loss: 0.0326\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0386 - val_loss: 0.0223\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0311 - val_loss: 0.0273\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0316 - val_loss: 0.0319\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0315 - val_loss: 0.0313\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0298 - val_loss: 0.0289\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0274 - val_loss: 0.0284\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0287 - val_loss: 0.0277\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0320 - val_loss: 0.0231\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0284 - val_loss: 0.0163\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0224 - val_loss: 0.0120\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0199 - val_loss: 0.0109\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0186 - val_loss: 0.0104\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0181 - val_loss: 0.0090\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0074\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0068\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0139 - val_loss: 0.0061\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0112 - val_loss: 0.0056\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0149 - val_loss: 0.0050\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0144 - val_loss: 0.0053\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0141 - val_loss: 0.0059\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0147 - val_loss: 0.0063\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0139 - val_loss: 0.0071\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0113 - val_loss: 0.0063\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0109 - val_loss: 0.0050\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0103 - val_loss: 0.0046\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0100 - val_loss: 0.0046\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0101 - val_loss: 0.0050\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0078 - val_loss: 0.0038\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.1452e-04 - val_loss: 0.0023\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9596e-04 - val_loss: 0.0021\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.0881e-04 - val_loss: 0.0020\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.4554e-04 - val_loss: 0.0021\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.2429e-04 - val_loss: 0.0022\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.6616e-04 - val_loss: 0.0022\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.1274e-04 - val_loss: 0.0020\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.5073e-04 - val_loss: 0.0019\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.8448e-04 - val_loss: 0.0019\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.6773e-04 - val_loss: 0.0020\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1700e-04 - val_loss: 0.0021\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5221e-04 - val_loss: 0.0021\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0965e-04 - val_loss: 0.0021\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7307e-04 - val_loss: 0.0020\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2780e-04 - val_loss: 0.0019\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3534e-04 - val_loss: 0.0019\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2352e-04 - val_loss: 0.0020\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1097e-04 - val_loss: 0.0020\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7513e-04 - val_loss: 0.0020\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3896e-04 - val_loss: 0.0019\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.4163e-05 - val_loss: 0.0018\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.8985e-05 - val_loss: 0.0019\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.2146e-05 - val_loss: 0.0019\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.2962e-05 - val_loss: 0.0019\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.4345e-05 - val_loss: 0.0019\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4091e-05 - val_loss: 0.0018\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5556e-05 - val_loss: 0.0018\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.2272e-05 - val_loss: 0.0018\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6926e-05 - val_loss: 0.0018\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.6379e-05 - val_loss: 0.0019\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.2714e-05 - val_loss: 0.0019\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.6119e-05 - val_loss: 0.0019\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4094e-05 - val_loss: 0.0018\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.9628e-05 - val_loss: 0.0018\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9678e-05 - val_loss: 0.0018\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.8517e-05 - val_loss: 0.0018\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3344e-05 - val_loss: 0.0018\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7946e-05 - val_loss: 0.0018\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4239e-05 - val_loss: 0.0018\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3113e-05 - val_loss: 0.0018\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2345e-05 - val_loss: 0.0018\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3607e-05 - val_loss: 0.0018\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2182e-05 - val_loss: 0.0018\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5586e-05 - val_loss: 0.0018\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0122e-05 - val_loss: 0.0018\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.8390e-06 - val_loss: 0.0018\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2155e-05 - val_loss: 0.0018\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9583e-06 - val_loss: 0.0018\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3752e-06 - val_loss: 0.0018\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5080e-05 - val_loss: 0.0018\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9822e-06 - val_loss: 0.0018\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4454e-05 - val_loss: 0.0018\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7390e-06 - val_loss: 0.0018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2723e-05 - val_loss: 0.0018\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0493e-05 - val_loss: 0.0018\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1268e-06 - val_loss: 0.0018\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4854e-06 - val_loss: 0.0018\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8015e-06 - val_loss: 0.0018\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0596e-06 - val_loss: 0.0018\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7904e-06 - val_loss: 0.0018\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.4336e-06 - val_loss: 0.0018\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7498e-06 - val_loss: 0.0018\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6985e-06 - val_loss: 0.0018\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6011e-06 - val_loss: 0.0018\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8116e-06 - val_loss: 0.0018\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5892e-06 - val_loss: 0.0018\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8594e-06 - val_loss: 0.0018\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7168e-06 - val_loss: 0.0018\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7731e-06 - val_loss: 0.0018\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4359e-06 - val_loss: 0.0018\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.1838e-07 - val_loss: 0.0018\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6287e-07 - val_loss: 0.0018\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0195e-06 - val_loss: 0.0018\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0102e-07 - val_loss: 0.0018\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.8486e-07 - val_loss: 0.0018\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.3542e-07 - val_loss: 0.0018\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.6322e-07 - val_loss: 0.0018\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2415e-07 - val_loss: 0.0018\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.0456e-07 - val_loss: 0.0018\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3089e-07 - val_loss: 0.0018\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.9754e-07 - val_loss: 0.0018\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.2908e-07 - val_loss: 0.0018\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5878e-07 - val_loss: 0.0018\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4925e-07 - val_loss: 0.0018\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3268e-07 - val_loss: 0.0018\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1509e-07 - val_loss: 0.0018\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6976e-07 - val_loss: 0.0018\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9437e-07 - val_loss: 0.0018\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.1579e-08 - val_loss: 0.0018\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2765e-07 - val_loss: 0.0018\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.4540e-08 - val_loss: 0.0018\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.1086e-08 - val_loss: 0.0018\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.3840e-08 - val_loss: 0.0018\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4860e-08 - val_loss: 0.0018\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.9320e-08 - val_loss: 0.0018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8413e-08 - val_loss: 0.0018\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7260e-08 - val_loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "o = ordinaryAE.fit(beanIntensities, beanIntensities, epochs=200, verbose = True, validation_data=(validation, validation))\n",
    "#print(o.history['loss'][-1]) #the final loss "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Parent AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLinearSuperParent(tf.keras.layers.Layer):\n",
    "    def __init__(self, rgm, oldrgm, input_dim=32, units=32):\n",
    "        super(EncoderLinearSuperParent, self).__init__()\n",
    "        self.rgm = rgm\n",
    "        self.OGrgm = oldrgm\n",
    "        \n",
    "        def init_weights(shape, dtype=\"float32\"):\n",
    "\n",
    "            w_init = tf.random_normal_initializer()(shape=shape, dtype=dtype) * tf.convert_to_tensor(self.OGrgm, dtype=dtype)\n",
    "\n",
    "            return w_init\n",
    "        \n",
    "\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=init_weights(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        return tf.matmul(X, tf.multiply(self.rgm, self.w))\n",
    "    #tf.matmul(inputs, self.w)\n",
    "\n",
    "class DecoderLinearSuperParent(tf.keras.layers.Layer):\n",
    "    def __init__(self, rgm, oldrgm, input_dim=32, units=32):\n",
    "        super(DecoderLinearSuperParent, self).__init__()\n",
    "        self.rgm = rgm\n",
    "        self.OGrgm = oldrgm\n",
    "\n",
    "        def init_weights(shape, dtype=\"float32\"):\n",
    "\n",
    "            w_init = tf.random_normal_initializer()(shape=shape, dtype=dtype) * tf.transpose(tf.convert_to_tensor(self.rgm, dtype=dtype))\n",
    "\n",
    "            return w_init\n",
    "    \n",
    "        \n",
    "        self.w = tf.Variable(\n",
    "            initial_value=init_weights(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        #return tf.matmul(X, tf.multiply((self.rgm), self.w))\n",
    "        X = tf.matmul(X, tf.multiply(tf.transpose(self.rgm), self.w)) \n",
    "        #return tf.matmul(inputs, self.w)\n",
    "        # v = tf.zeros_like(X)\n",
    "        # u = tf.ones_like(X)\n",
    "        # u = tf.math.scalar_mul(-3.0, u)\n",
    "        \n",
    "        return X#tf.where(tf.math.less(X, v), u, X) #where X is less than 0, return -1 \n",
    "        \n",
    "        \n",
    "def encoder(parent_child_biological_association, num_hidden_units=21):\n",
    "    '''\n",
    "    Encoder structure\n",
    "    '''\n",
    "    '''\n",
    "    The data is time-series. Therefore, CNN to learn the temporal relationship between \n",
    "    the intensities for each gene.\n",
    "    '''\n",
    "    en_conv = Conv1D(32, 3, activation = \"relu\")(parent_child_biological_association) # 6*NUM_TARGETS\n",
    "    en_dense = Flatten()(en_conv)\n",
    "    phenotype = Dense(num_hidden_units)(en_dense)\n",
    "    return phenotype\n",
    "\n",
    "def decoder(X, num_protein_gene, time_steps):\n",
    "    '''\n",
    "    Decoder structure\n",
    "    '''\n",
    "    de_dense = Dense(128)(X)\n",
    "    de_dense = Reshape((1, 128))(de_dense) #tf.reshape(de_dense, (self.batch_size,1,128))\n",
    "    de_deconv = Conv1DTranspose(num_protein_gene, time_steps, activation = \"relu\")(de_dense) #used to be transpose\n",
    "    #de_deconv = Conv1D(num_protein_gene, time_steps, activation = \"relu\")(de_dense) \n",
    "    # gene_reconstruction = self.decoder_biological_operation(de_deconv)\n",
    "    return de_deconv\n",
    "\n",
    "def modelSuperParent(rgm, oldRGM, num_protein_gene, time_steps, num_kinase_regulators, num_hidden_units = 21): #rgm is set to superparent, oldrgm is original rgm unmodified\n",
    "    inp = Input(shape=(time_steps, num_kinase_regulators))\n",
    "    x = EncoderLinearSuperParent(rgm, oldRGM, NUM_TARGETS, NUM_TARGETS)(inp)\n",
    "    enc = encoder(x, num_hidden_units)\n",
    "    dec = decoder(enc, num_protein_gene, time_steps)\n",
    "    out = DecoderLinearSuperParent(rgm, oldRGM, NUM_TARGETS, NUM_TARGETS)(dec)\n",
    "\n",
    "    _model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelSuperParentSequential(rgm, oldRGM, num_protein_gene, time_steps, num_kinase_regulators, num_hidden_units = 21): #rgm is set to superparent, oldrgm is original rgm unmodified\n",
    "    m = tf.keras.Sequential()\n",
    "    inp = Input(shape=(time_steps, num_kinase_regulators))\n",
    "    x = EncoderLinearSuperParent(rgm, oldRGM, NUM_TARGETS, NUM_TARGETS)(inp)\n",
    "    enc = encoder(x, num_hidden_units)\n",
    "    dec = decoder(enc, num_protein_gene, time_steps)\n",
    "    out = DecoderLinearSuperParent(rgm, oldRGM, NUM_TARGETS, NUM_TARGETS)(dec)\n",
    "\n",
    "    _model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2195 - val_loss: 0.2456\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2225 - val_loss: 0.2228\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2095 - val_loss: 0.1863\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1804 - val_loss: 0.1362\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1400 - val_loss: 0.0739\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0901 - val_loss: 0.0209\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0495 - val_loss: 0.0306\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0602 - val_loss: 0.0464\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0686 - val_loss: 0.0230\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0414 - val_loss: 0.0062\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0196 - val_loss: 0.0094\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0157 - val_loss: 0.0214\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0205 - val_loss: 0.0313\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0279 - val_loss: 0.0355\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0277 - val_loss: 0.0339\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0213 - val_loss: 0.0287\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0175 - val_loss: 0.0226\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0135 - val_loss: 0.0178\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0173 - val_loss: 0.0079\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - val_loss: 0.0074\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0043 - val_loss: 0.0085\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.7683e-04 - val_loss: 0.0021\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.4249e-04 - val_loss: 0.0019\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.2573e-04 - val_loss: 0.0019\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.7912e-04 - val_loss: 0.0023\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.4560e-04 - val_loss: 0.0020\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.6352e-04 - val_loss: 0.0020\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.1370e-04 - val_loss: 0.0023\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4473e-04 - val_loss: 0.0025\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2864e-04 - val_loss: 0.0025\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7009e-04 - val_loss: 0.0021\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1823e-04 - val_loss: 0.0018\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5234e-04 - val_loss: 0.0017\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6950e-04 - val_loss: 0.0017\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8296e-04 - val_loss: 0.0018\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8954e-04 - val_loss: 0.0019\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8968e-04 - val_loss: 0.0020\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3070e-04 - val_loss: 0.0021\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0042e-04 - val_loss: 0.0023\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8039e-04 - val_loss: 0.0023\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4393e-04 - val_loss: 0.0021\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.2304e-05 - val_loss: 0.0019\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3539e-04 - val_loss: 0.0019\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7234e-04 - val_loss: 0.0019\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.1851e-05 - val_loss: 0.0019\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6392e-05 - val_loss: 0.0019\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3504e-05 - val_loss: 0.0020\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9977e-05 - val_loss: 0.0019\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.2861e-05 - val_loss: 0.0019\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8928e-05 - val_loss: 0.0018\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8725e-05 - val_loss: 0.0018\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0256e-05 - val_loss: 0.0018\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.6428e-05 - val_loss: 0.0018\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6947e-05 - val_loss: 0.0018\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0664e-05 - val_loss: 0.0019\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2757e-05 - val_loss: 0.0019\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9166e-05 - val_loss: 0.0019\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6238e-05 - val_loss: 0.0019\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5079e-05 - val_loss: 0.0018\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.6027e-06 - val_loss: 0.0018\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3319e-05 - val_loss: 0.0018\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3169e-05 - val_loss: 0.0018\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.0483e-06 - val_loss: 0.0018\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3575e-06 - val_loss: 0.0019\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0644e-05 - val_loss: 0.0019\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2272e-05 - val_loss: 0.0019\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.2217e-06 - val_loss: 0.0018\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4966e-06 - val_loss: 0.0018\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.5511e-06 - val_loss: 0.0018\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.3431e-06 - val_loss: 0.0018\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.8437e-06 - val_loss: 0.0019\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7885e-06 - val_loss: 0.0019\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3883e-06 - val_loss: 0.0019\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.0669e-06 - val_loss: 0.0019\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.5058e-06 - val_loss: 0.0019\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8691e-06 - val_loss: 0.0018\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7548e-06 - val_loss: 0.0018\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7788e-06 - val_loss: 0.0019\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6927e-06 - val_loss: 0.0019\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7929e-06 - val_loss: 0.0019\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4338e-06 - val_loss: 0.0019\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.8177e-06 - val_loss: 0.0019\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1472e-06 - val_loss: 0.0019\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.5474e-07 - val_loss: 0.0019\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2543e-06 - val_loss: 0.0019\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0981e-06 - val_loss: 0.0018\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4698e-06 - val_loss: 0.0018\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3525e-06 - val_loss: 0.0018\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2587e-06 - val_loss: 0.0018\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6092e-06 - val_loss: 0.0018\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4694e-06 - val_loss: 0.0018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2403e-06 - val_loss: 0.0019\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.1876e-07 - val_loss: 0.0019\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3780e-06 - val_loss: 0.0019\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.5651e-07 - val_loss: 0.0019\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.4403e-07 - val_loss: 0.0019\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.0479e-07 - val_loss: 0.0019\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2434e-06 - val_loss: 0.0019\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2881e-07 - val_loss: 0.0018\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3055e-06 - val_loss: 0.0018\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2391e-07 - val_loss: 0.0018\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0212e-07 - val_loss: 0.0018\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.5007e-07 - val_loss: 0.0018\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.3455e-07 - val_loss: 0.0018\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8984e-07 - val_loss: 0.0018\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9833e-07 - val_loss: 0.0018\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7904e-07 - val_loss: 0.0018\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4479e-07 - val_loss: 0.0019\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3324e-07 - val_loss: 0.0019\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6289e-07 - val_loss: 0.0019\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6901e-07 - val_loss: 0.0019\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2836e-07 - val_loss: 0.0019\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6090e-07 - val_loss: 0.0019\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6375e-07 - val_loss: 0.0019\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2380e-07 - val_loss: 0.0018\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2100e-07 - val_loss: 0.0018\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1163e-07 - val_loss: 0.0018\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2636e-07 - val_loss: 0.0018\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8923e-07 - val_loss: 0.0019\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6339e-07 - val_loss: 0.0019\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5753e-07 - val_loss: 0.0019\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3877e-07 - val_loss: 0.0018\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.8251e-08 - val_loss: 0.0018\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3679e-08 - val_loss: 0.0018\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6325e-07 - val_loss: 0.0018\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2877e-08 - val_loss: 0.0018\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9053e-07 - val_loss: 0.0018\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1773e-08 - val_loss: 0.0018\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.6068e-08 - val_loss: 0.0018\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6563e-07 - val_loss: 0.0018\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4922e-07 - val_loss: 0.0018\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3110e-07 - val_loss: 0.0018\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2148e-07 - val_loss: 0.0018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.5378e-08 - val_loss: 0.0018\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.9033e-08 - val_loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "looseParent = modelSuperParent(superParent, regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS, 32)\n",
    "looseParent.compile(optimizer='adam', loss=ignore_noParent_MSE)\n",
    "o = looseParent.fit(beanIntensities, beanIntensities, epochs=200, verbose = True,  validation_data=(validation, validation))\n",
    "#print(o.history['loss'][-1]) #the final loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNetAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a second copy of the layers which will be modified to be a denseNET auto encoder\n",
    "'''\n",
    "#TODO: fix call to map to -1?\n",
    "class DenseEncoderLinear2(tf.keras.layers.Layer): #TODO: Fix the decoder to -1\n",
    "    def __init__(self, rgm, oldrgm, input_dim=32, units=32):\n",
    "        super(DenseEncoderLinear2, self).__init__()\n",
    "        self.rgm = rgm\n",
    "        self.oldrgm = oldrgm\n",
    "        \n",
    "        def init_weights(shape, dtype=\"float32\"):\n",
    "\n",
    "            w_init = tf.random_normal_initializer()(shape=shape, dtype=dtype) * tf.convert_to_tensor(self.oldrgm, dtype=dtype)\n",
    "\n",
    "            return w_init\n",
    "        \n",
    "\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=init_weights(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        return tf.matmul(X, tf.multiply(self.rgm, self.w))\n",
    "    #tf.matmul(inputs, self.w)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"rgm\": self.rgm,\n",
    "            \"oldrgm\": self.oldrgm,\n",
    "            'input_dim': 32,\n",
    "            'units' : 32\n",
    "        })\n",
    "\n",
    "class DenseDecoderLinear2(tf.keras.layers.Layer):\n",
    "    def __init__(self, rgm, oldrgm, input_dim=32, units=32):\n",
    "        super(DenseDecoderLinear2, self).__init__()\n",
    "        self.rgm = rgm\n",
    "        self.oldrgm = oldrgm\n",
    "\n",
    "        def init_weights(shape, dtype=\"float32\"):\n",
    "\n",
    "            w_init = tf.random_normal_initializer()(shape=shape, dtype=dtype) * tf.transpose(tf.convert_to_tensor(self.oldrgm, dtype=dtype))\n",
    "\n",
    "            return w_init\n",
    "\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=init_weights(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        #return tf.matmul(X, tf.multiply((self.rgm), self.w))\n",
    "        return tf.matmul(X, tf.multiply(tf.transpose(self.rgm), self.w)) #used to have a transpose\n",
    "        #return tf.matmul(inputs, self.w)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"rgm\": self.rgm,\n",
    "            \"oldrgm\": self.oldrgm,\n",
    "            'input_dim': 32,\n",
    "            'units' : 32\n",
    "        })\n",
    "        \n",
    "\n",
    "def denseencoder2(parent_child_biological_association, inp, num_hidden_units=21):\n",
    "    '''\n",
    "    Encoder structure\n",
    "    '''\n",
    "    '''\n",
    "    The data is time-series. Therefore, CNN to learn the temporal relationship between \n",
    "    the intensities for each gene.\n",
    "    '''\n",
    "    en_conv = Conv1D(490, 3, activation = \"tanh\")(parent_child_biological_association) # 6*NUM_TARGETS\n",
    "    en_dense = Flatten()(en_conv)\n",
    "    inp = Flatten()(inp)\n",
    "    #print(en_dense.shape, inp.shape)\n",
    "    d = Concatenate()([en_dense, inp]) #dense layer\n",
    "    o_d = Dense(1024, activation = 'tanh')(d) #added a layer\n",
    "    c = Concatenate()([o_d, d]) #TOTALY NEW LAYER\n",
    "    en_dense = Dense(128, activation = 'tanh')(c) #TOTALY NEW LAYER\n",
    "    \n",
    "    phenotype = Dense(num_hidden_units, activation=\"tanh\")(d)\n",
    "    return phenotype\n",
    "\n",
    "def densedecoder2(X, num_protein_gene, time_steps):\n",
    "    '''\n",
    "    Decoder structure\n",
    "    '''\n",
    "    de_dense = Dense(784, activation = 'tanh')(X)\n",
    "    de_dense = Dense(512, activation = 'tanh')(de_dense) #TOTALY NEW LAYER\n",
    "    de_dense = Dense(256, activation = 'tanh')(de_dense) #added a layer\n",
    "    de_dense = Reshape((1, 256))(de_dense) #tf.reshape(de_dense, (self.batch_size,1,128))\n",
    "    de_deconv = Conv1DTranspose(num_protein_gene, time_steps, activation = \"tanh\")(de_dense) #used to be transpose\n",
    "    #de_deconv = Conv1D(num_protein_gene, time_steps, activation = \"relu\")(de_dense) \n",
    "    # gene_reconstruction = self.decoder_biological_operation(de_deconv)\n",
    "    return de_deconv\n",
    "\n",
    "def modelDense2(rgm, oldrgm, num_protein_gene, time_steps, num_kinase_regulators, num_hidden_units = 21):\n",
    "    inp = Input(shape=(time_steps, num_kinase_regulators))\n",
    "    x = DenseEncoderLinear2(rgm, oldrgm, NUM_TARGETS, NUM_TARGETS)(inp)\n",
    "    #x = EncoderLinear2(x)\n",
    "    enc = denseencoder2(x, inp, num_hidden_units)\n",
    "    dec = densedecoder2(enc, num_protein_gene, time_steps)\n",
    "    out = DenseDecoderLinear2(rgm, oldrgm, NUM_TARGETS, NUM_TARGETS)(dec)\n",
    "\n",
    "    _model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2230 - val_loss: 0.2681\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2166 - val_loss: 0.1443\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1166 - val_loss: 0.0645\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0641 - val_loss: 0.0208\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0386 - val_loss: 0.0092\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0241 - val_loss: 0.0280\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0235 - val_loss: 0.0471\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0303 - val_loss: 0.0357\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0207 - val_loss: 0.0136\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0074\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0153 - val_loss: 0.0082\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0141 - val_loss: 0.0170\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0124 - val_loss: 0.0155\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0107 - val_loss: 0.0148\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0118 - val_loss: 0.0160\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0109 - val_loss: 0.0168\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0126\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0097 - val_loss: 0.0122\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0107\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0113\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0075 - val_loss: 0.0124\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0078 - val_loss: 0.0118\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0107\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0072 - val_loss: 0.0090\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0070 - val_loss: 0.0094\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0070 - val_loss: 0.0093\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0098\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0101\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0098\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0088\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0096\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0100\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0093\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - val_loss: 0.0090\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - val_loss: 0.0096\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - val_loss: 0.0096\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - val_loss: 0.0090\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - val_loss: 0.0097\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - val_loss: 0.0083\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - val_loss: 0.0075\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - val_loss: 0.0431\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0208 - val_loss: 0.0069\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0281 - val_loss: 0.0031\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0126 - val_loss: 0.0186\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0104 - val_loss: 0.0323\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0158 - val_loss: 0.0233\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0109 - val_loss: 0.0037\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0107 - val_loss: 0.0070\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0089 - val_loss: 0.0129\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0088 - val_loss: 0.0166\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0087 - val_loss: 0.0178\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0085 - val_loss: 0.0167\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0087 - val_loss: 0.0130\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0075 - val_loss: 0.0123\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - val_loss: 0.0125\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - val_loss: 0.0119\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0078 - val_loss: 0.0111\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0163 - val_loss: 0.0098\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0083 - val_loss: 0.0122\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0074 - val_loss: 0.0112\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0070 - val_loss: 0.0098\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - val_loss: 0.0106\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0069 - val_loss: 0.0106\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - val_loss: 0.0102\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - val_loss: 0.0097\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29839e70ca0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = modelDense2(superParent, regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS, 32)\n",
    "dense.compile(optimizer='adam', loss=ignore_noParent_MSE)\n",
    "dense.fit(beanIntensities, beanIntensities, epochs=200,  verbose=True, validation_data=(validation, validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 11, 372)]    0           []                               \n",
      "                                                                                                  \n",
      " dense_encoder_linear2 (DenseEn  (None, 11, 372)     138384      ['input_3[0][0]']                \n",
      " coderLinear2)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 9, 490)       547330      ['dense_encoder_linear2[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 4410)         0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 4092)         0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8502)         0           ['flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           272096      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 784)          25872       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 512)          401920      ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          131328      ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 256)       0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_transpose_2 (Conv1DTran  (None, 11, 372)     1047924     ['reshape_2[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " dense_decoder_linear2 (DenseDe  (None, 11, 372)     138384      ['conv1d_transpose_2[0][0]']     \n",
      " coderLinear2)                                                                                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,703,238\n",
      "Trainable params: 2,703,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 11, 372)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = dense.predict(validation)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(o.reshape(11,372))\n",
    "v = pd.DataFrame(validation.reshape(11,372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>117</th>\n",
       "      <th>131</th>\n",
       "      <th>164</th>\n",
       "      <th>225</th>\n",
       "      <th>259</th>\n",
       "      <th>334</th>\n",
       "      <th>350</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.486155</td>\n",
       "      <td>0.330041</td>\n",
       "      <td>0.409118</td>\n",
       "      <td>0.470490</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.493227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.361249</td>\n",
       "      <td>0.485207</td>\n",
       "      <td>0.431209</td>\n",
       "      <td>0.449812</td>\n",
       "      <td>0.556959</td>\n",
       "      <td>0.482214</td>\n",
       "      <td>0.485158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.331437</td>\n",
       "      <td>0.394736</td>\n",
       "      <td>0.437545</td>\n",
       "      <td>0.380384</td>\n",
       "      <td>0.568960</td>\n",
       "      <td>0.485805</td>\n",
       "      <td>0.467526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.008046</td>\n",
       "      <td>-1.000520</td>\n",
       "      <td>-1.179355</td>\n",
       "      <td>-0.867316</td>\n",
       "      <td>-0.496467</td>\n",
       "      <td>-0.995643</td>\n",
       "      <td>-0.338227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347649</td>\n",
       "      <td>0.391867</td>\n",
       "      <td>0.380998</td>\n",
       "      <td>0.432072</td>\n",
       "      <td>0.461896</td>\n",
       "      <td>0.436251</td>\n",
       "      <td>0.494369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.301823</td>\n",
       "      <td>0.418512</td>\n",
       "      <td>0.299265</td>\n",
       "      <td>0.254463</td>\n",
       "      <td>0.529659</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.486561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.387590</td>\n",
       "      <td>0.447562</td>\n",
       "      <td>0.421540</td>\n",
       "      <td>0.425726</td>\n",
       "      <td>0.587291</td>\n",
       "      <td>0.477551</td>\n",
       "      <td>0.499841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015175</td>\n",
       "      <td>0.012164</td>\n",
       "      <td>-0.071924</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>-0.048788</td>\n",
       "      <td>0.016630</td>\n",
       "      <td>-0.014107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.318266</td>\n",
       "      <td>0.437179</td>\n",
       "      <td>0.383670</td>\n",
       "      <td>0.378476</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.431510</td>\n",
       "      <td>0.488008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.328387</td>\n",
       "      <td>0.471900</td>\n",
       "      <td>0.282996</td>\n",
       "      <td>0.240095</td>\n",
       "      <td>0.536652</td>\n",
       "      <td>0.461603</td>\n",
       "      <td>0.486150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.374247</td>\n",
       "      <td>0.390915</td>\n",
       "      <td>0.574866</td>\n",
       "      <td>0.474872</td>\n",
       "      <td>0.512475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         117       131       164       225       259       334       350\n",
       "0   0.318467  0.486155  0.330041  0.409118  0.470490  0.362110  0.493227\n",
       "1   0.361249  0.485207  0.431209  0.449812  0.556959  0.482214  0.485158\n",
       "2   0.331437  0.394736  0.437545  0.380384  0.568960  0.485805  0.467526\n",
       "3  -1.008046 -1.000520 -1.179355 -0.867316 -0.496467 -0.995643 -0.338227\n",
       "4   0.347649  0.391867  0.380998  0.432072  0.461896  0.436251  0.494369\n",
       "5   0.301823  0.418512  0.299265  0.254463  0.529659  0.373047  0.486561\n",
       "6   0.387590  0.447562  0.421540  0.425726  0.587291  0.477551  0.499841\n",
       "7   0.015175  0.012164 -0.071924  0.005428 -0.048788  0.016630 -0.014107\n",
       "8   0.318266  0.437179  0.383670  0.378476  0.521667  0.431510  0.488008\n",
       "9   0.328387  0.471900  0.282996  0.240095  0.536652  0.461603  0.486150\n",
       "10  0.342657  0.463519  0.374247  0.390915  0.574866  0.474872  0.512475"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[parent_idx].head(NUM_TIME_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>117</th>\n",
       "      <th>131</th>\n",
       "      <th>164</th>\n",
       "      <th>225</th>\n",
       "      <th>259</th>\n",
       "      <th>334</th>\n",
       "      <th>350</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.464054</td>\n",
       "      <td>0.445813</td>\n",
       "      <td>0.475648</td>\n",
       "      <td>0.475451</td>\n",
       "      <td>0.601666</td>\n",
       "      <td>0.538352</td>\n",
       "      <td>0.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464782</td>\n",
       "      <td>0.410751</td>\n",
       "      <td>0.479145</td>\n",
       "      <td>0.469503</td>\n",
       "      <td>0.615856</td>\n",
       "      <td>0.581054</td>\n",
       "      <td>0.521357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.448974</td>\n",
       "      <td>0.424922</td>\n",
       "      <td>0.462434</td>\n",
       "      <td>0.489874</td>\n",
       "      <td>0.618050</td>\n",
       "      <td>0.541640</td>\n",
       "      <td>0.511626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.448781</td>\n",
       "      <td>0.442738</td>\n",
       "      <td>0.473856</td>\n",
       "      <td>0.468686</td>\n",
       "      <td>0.588641</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.528962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.375646</td>\n",
       "      <td>0.487818</td>\n",
       "      <td>0.385170</td>\n",
       "      <td>0.420683</td>\n",
       "      <td>0.515270</td>\n",
       "      <td>0.469018</td>\n",
       "      <td>0.508054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.506284</td>\n",
       "      <td>0.412253</td>\n",
       "      <td>0.486031</td>\n",
       "      <td>0.449196</td>\n",
       "      <td>0.638067</td>\n",
       "      <td>0.580319</td>\n",
       "      <td>0.503012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.469681</td>\n",
       "      <td>0.415919</td>\n",
       "      <td>0.528647</td>\n",
       "      <td>0.509842</td>\n",
       "      <td>0.595536</td>\n",
       "      <td>0.563962</td>\n",
       "      <td>0.527670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.470147</td>\n",
       "      <td>0.484273</td>\n",
       "      <td>0.481506</td>\n",
       "      <td>0.631007</td>\n",
       "      <td>0.569937</td>\n",
       "      <td>0.540709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.525481</td>\n",
       "      <td>0.414705</td>\n",
       "      <td>0.491357</td>\n",
       "      <td>0.473794</td>\n",
       "      <td>0.641192</td>\n",
       "      <td>0.572485</td>\n",
       "      <td>0.556883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         117       131       164       225       259       334       350\n",
       "0   0.464054  0.445813  0.475648  0.475451  0.601666  0.538352  0.517300\n",
       "1   0.464782  0.410751  0.479145  0.469503  0.615856  0.581054  0.521357\n",
       "2   0.448974  0.424922  0.462434  0.489874  0.618050  0.541640  0.511626\n",
       "3  -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
       "4   0.448781  0.442738  0.473856  0.468686  0.588641  0.488964  0.528962\n",
       "5   0.375646  0.487818  0.385170  0.420683  0.515270  0.469018  0.508054\n",
       "6   0.506284  0.412253  0.486031  0.449196  0.638067  0.580319  0.503012\n",
       "7  -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
       "8   0.469681  0.415919  0.528647  0.509842  0.595536  0.563962  0.527670\n",
       "9   0.462067  0.470147  0.484273  0.481506  0.631007  0.569937  0.540709\n",
       "10  0.525481  0.414705  0.491357  0.473794  0.641192  0.572485  0.556883"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[parent_idx].head(NUM_TIME_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.009282802>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_noParent_MSE(validation, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Space Size Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Fin Amin\\Desktop\\StemCellResearch\\beanEncoder\\BeanEncoderMain.ipynb Cell 46\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fin%20Amin/Desktop/StemCellResearch/beanEncoder/BeanEncoderMain.ipynb#X63sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m dense \u001b[39m=\u001b[39m modelDense2(superParent, regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS, value)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fin%20Amin/Desktop/StemCellResearch/beanEncoder/BeanEncoderMain.ipynb#X63sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m dense\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39mignore_noParent_MSE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Fin%20Amin/Desktop/StemCellResearch/beanEncoder/BeanEncoderMain.ipynb#X63sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m dense\u001b[39m.\u001b[39;49mfit(beanIntensities, beanIntensities, epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,  verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fin%20Amin/Desktop/StemCellResearch/beanEncoder/BeanEncoderMain.ipynb#X63sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m test_hat \u001b[39m=\u001b[39m dense(validation) \u001b[39m#, verbose = 0)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fin%20Amin/Desktop/StemCellResearch/beanEncoder/BeanEncoderMain.ipynb#X63sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m loss \u001b[39m=\u001b[39m ignore_noParent_MSE(validation, test_hat)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2630\u001b[0m         args,\n\u001b[0;32m   2631\u001b[0m         kwargs,\n\u001b[0;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1116\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1117\u001b[0m       original_func,\n\u001b[0;32m   1118\u001b[0m       args,\n\u001b[0;32m   1119\u001b[0m       kwargs,\n\u001b[0;32m   1120\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1121\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1122\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1123\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1124\u001b[0m       ))\n\u001b[0;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\FINAMI~1\\AppData\\Local\\Temp\\__autograph_generated_filemc4x55c2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1038\u001b[0m       run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1039\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1040\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1041\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1031\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:893\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    892\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    894\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:537\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m   \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[39m  This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    538\u001b[0m       loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    539\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:590\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    588\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gradients(tape, loss, var_list, grad_loss)\n\u001b[0;32m    592\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes([\n\u001b[0;32m    593\u001b[0m     v \u001b[39mfor\u001b[39;00m g, v \u001b[39min\u001b[39;00m grads_and_vars\n\u001b[0;32m    594\u001b[0m     \u001b[39mif\u001b[39;00m g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m v\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m tf\u001b[39m.\u001b[39mresource\n\u001b[0;32m    595\u001b[0m ])\n\u001b[0;32m    597\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:471\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    470\u001b[0m   \u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m   grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    472\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1102\u001b[0m     flat_targets,\n\u001b[0;32m   1103\u001b[0m     flat_sources,\n\u001b[0;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:121\u001b[0m, in \u001b[0;36m_IfGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39massert\u001b[39;00m false_graph\u001b[39m.\u001b[39mouter_graph \u001b[39m==\u001b[39m if_op\u001b[39m.\u001b[39mgraph\n\u001b[0;32m    118\u001b[0m \u001b[39m# Create grad functions that compute the gradient of the true/false forward\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m# graphs. These functions will capture tensors from the forward pass\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m true_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    122\u001b[0m     true_graph, grads, util\u001b[39m.\u001b[39;49munique_grad_fn_name(true_graph\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m    123\u001b[0m false_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    124\u001b[0m     false_graph, grads, util\u001b[39m.\u001b[39munique_grad_fn_name(false_graph\u001b[39m.\u001b[39mname))\n\u001b[0;32m    126\u001b[0m \u001b[39m# Replaces output None grads with zeros if at least one branch has non-None\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m# grad at that index.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:430\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[1;34m(func_graph, grads, name)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grad_func\u001b[39m(func_graph, grads, name):\n\u001b[0;32m    429\u001b[0m   \u001b[39m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m   \u001b[39mreturn\u001b[39;00m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    431\u001b[0m       name,\n\u001b[0;32m    432\u001b[0m       \u001b[39mlambda\u001b[39;49;00m: _grad_fn(func_graph, grads), [], {},\n\u001b[0;32m    433\u001b[0m       func_graph\u001b[39m=\u001b[39;49m_CondGradFuncGraph(name, func_graph))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:432\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grad_func\u001b[39m(func_graph, grads, name):\n\u001b[0;32m    429\u001b[0m   \u001b[39m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[39;00m\n\u001b[0;32m    430\u001b[0m   \u001b[39mreturn\u001b[39;00m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    431\u001b[0m       name,\n\u001b[1;32m--> 432\u001b[0m       \u001b[39mlambda\u001b[39;00m: _grad_fn(func_graph, grads), [], {},\n\u001b[0;32m    433\u001b[0m       func_graph\u001b[39m=\u001b[39m_CondGradFuncGraph(name, func_graph))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:421\u001b[0m, in \u001b[0;36m_grad_fn\u001b[1;34m(func_graph, grads)\u001b[0m\n\u001b[0;32m    415\u001b[0m   grad_ys\u001b[39m.\u001b[39mappend(grad_y)\n\u001b[0;32m    417\u001b[0m \u001b[39m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39m# in _resolve_grad_inputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(\n\u001b[0;32m    422\u001b[0m     ys, func_graph\u001b[39m.\u001b[39;49minputs, grad_ys\u001b[39m=\u001b[39;49mgrad_ys,\n\u001b[0;32m    423\u001b[0m     src_graph\u001b[39m=\u001b[39;49mfunc_graph)\n\u001b[0;32m    425\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    696\u001b[0m                              \u001b[39mlambda\u001b[39;49;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:328\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    325\u001b[0m     xla_compile \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xla_compile:\n\u001b[1;32m--> 328\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn()  \u001b[39m# Exit early\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m# together with the non-gradient computation.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 696\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:121\u001b[0m, in \u001b[0;36m_IfGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39massert\u001b[39;00m false_graph\u001b[39m.\u001b[39mouter_graph \u001b[39m==\u001b[39m if_op\u001b[39m.\u001b[39mgraph\n\u001b[0;32m    118\u001b[0m \u001b[39m# Create grad functions that compute the gradient of the true/false forward\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m# graphs. These functions will capture tensors from the forward pass\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m true_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    122\u001b[0m     true_graph, grads, util\u001b[39m.\u001b[39;49munique_grad_fn_name(true_graph\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m    123\u001b[0m false_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    124\u001b[0m     false_graph, grads, util\u001b[39m.\u001b[39munique_grad_fn_name(false_graph\u001b[39m.\u001b[39mname))\n\u001b[0;32m    126\u001b[0m \u001b[39m# Replaces output None grads with zeros if at least one branch has non-None\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m# grad at that index.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:430\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[1;34m(func_graph, grads, name)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grad_func\u001b[39m(func_graph, grads, name):\n\u001b[0;32m    429\u001b[0m   \u001b[39m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m   \u001b[39mreturn\u001b[39;00m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    431\u001b[0m       name,\n\u001b[0;32m    432\u001b[0m       \u001b[39mlambda\u001b[39;49;00m: _grad_fn(func_graph, grads), [], {},\n\u001b[0;32m    433\u001b[0m       func_graph\u001b[39m=\u001b[39;49m_CondGradFuncGraph(name, func_graph))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:432\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grad_func\u001b[39m(func_graph, grads, name):\n\u001b[0;32m    429\u001b[0m   \u001b[39m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[39;00m\n\u001b[0;32m    430\u001b[0m   \u001b[39mreturn\u001b[39;00m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    431\u001b[0m       name,\n\u001b[1;32m--> 432\u001b[0m       \u001b[39mlambda\u001b[39;00m: _grad_fn(func_graph, grads), [], {},\n\u001b[0;32m    433\u001b[0m       func_graph\u001b[39m=\u001b[39m_CondGradFuncGraph(name, func_graph))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:421\u001b[0m, in \u001b[0;36m_grad_fn\u001b[1;34m(func_graph, grads)\u001b[0m\n\u001b[0;32m    415\u001b[0m   grad_ys\u001b[39m.\u001b[39mappend(grad_y)\n\u001b[0;32m    417\u001b[0m \u001b[39m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39m# in _resolve_grad_inputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(\n\u001b[0;32m    422\u001b[0m     ys, func_graph\u001b[39m.\u001b[39;49minputs, grad_ys\u001b[39m=\u001b[39;49mgrad_ys,\n\u001b[0;32m    423\u001b[0m     src_graph\u001b[39m=\u001b[39;49mfunc_graph)\n\u001b[0;32m    425\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    696\u001b[0m                              \u001b[39mlambda\u001b[39;49;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:328\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    325\u001b[0m     xla_compile \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xla_compile:\n\u001b[1;32m--> 328\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn()  \u001b[39m# Exit early\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m# together with the non-gradient computation.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 696\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:121\u001b[0m, in \u001b[0;36m_IfGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39massert\u001b[39;00m false_graph\u001b[39m.\u001b[39mouter_graph \u001b[39m==\u001b[39m if_op\u001b[39m.\u001b[39mgraph\n\u001b[0;32m    118\u001b[0m \u001b[39m# Create grad functions that compute the gradient of the true/false forward\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m# graphs. These functions will capture tensors from the forward pass\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m true_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    122\u001b[0m     true_graph, grads, util\u001b[39m.\u001b[39;49munique_grad_fn_name(true_graph\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m    123\u001b[0m false_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    124\u001b[0m     false_graph, grads, util\u001b[39m.\u001b[39munique_grad_fn_name(false_graph\u001b[39m.\u001b[39mname))\n\u001b[0;32m    126\u001b[0m \u001b[39m# Replaces output None grads with zeros if at least one branch has non-None\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m# grad at that index.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\cond_v2.py:430\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[1;34m(func_graph, grads, name)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grad_func\u001b[39m(func_graph, grads, name):\n\u001b[0;32m    429\u001b[0m   \u001b[39m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m   \u001b[39mreturn\u001b[39;00m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    431\u001b[0m       name,\n\u001b[0;32m    432\u001b[0m       \u001b[39mlambda\u001b[39;49;00m: _grad_fn(func_graph, grads), [], {},\n\u001b[0;32m    433\u001b[0m       func_graph\u001b[39m=\u001b[39;49m_CondGradFuncGraph(name, func_graph))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1145\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1141\u001b[0m   func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m   \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m   \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m-> 1145\u001b[0m   func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[0;32m   1146\u001b[0m       convert, func_outputs, expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1148\u001b[0m   check_func_mutation(func_args_before, func_kwargs_before, func_args,\n\u001b[0;32m   1149\u001b[0m                       func_kwargs, original_func)\n\u001b[0;32m   1150\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1104\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.convert\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1098\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo be compatible with tf.function, Python functions \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmust return zero or more Tensors or ExtensionTypes or None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1100\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues; in compilation of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(python_func)\u001b[39m}\u001b[39;00m\u001b[39m, found return \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalue of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, which is not a Tensor or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExtensionType.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1103\u001b[0m \u001b[39mif\u001b[39;00m add_control_dependencies:\n\u001b[1;32m-> 1104\u001b[0m   x \u001b[39m=\u001b[39m deps_ctx\u001b[39m.\u001b[39;49mmark_as_return(x)\n\u001b[0;32m   1105\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:249\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.mark_as_return\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    244\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor_array_ops\u001b[39m.\u001b[39mbuild_ta_with_new_flow(tensor, flow)\n\u001b[0;32m    245\u001b[0m \u001b[39m# We want to make the return values depend on the stateful operations, but\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39m# we don't want to introduce a cycle, so we make the return value the result\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39m# of a new identity operation that the stateful operations definitely don't\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[39m# depend on.\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m tensor \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49midentity(tensor)\n\u001b[0;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returned_tensors\u001b[39m.\u001b[39madd(tensor)\n\u001b[0;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py:295\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    292\u001b[0m   \u001b[39m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[0;32m    293\u001b[0m   \u001b[39m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 295\u001b[0m ret \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49midentity(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    296\u001b[0m \u001b[39m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_handle_data\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:4076\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4074\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   4075\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 4076\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   4077\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mIdentity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   4078\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   4079\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    692\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    693\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    696\u001b[0m     compute_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3751\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3752\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3753\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3754\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3755\u001b[0m       node_def,\n\u001b[0;32m   3756\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3757\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3758\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3759\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3760\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3761\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3762\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3763\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3764\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:2129\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2127\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2128\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> 2129\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   2130\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2131\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1933\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1931\u001b[0m inputs \u001b[39m=\u001b[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001b[39m.\u001b[39mattr)\n\u001b[0;32m   1932\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1933\u001b[0m op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(graph\u001b[39m.\u001b[39;49m_c_graph,\n\u001b[0;32m   1934\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1935\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1936\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1937\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #to test on entire DS: \n",
    "# N = 40\n",
    "# hidden = np.arange(2,24, 1) #range(1,32)\n",
    "# lossMatrix = []\n",
    "# for i in tqdm(range(N)):\n",
    "    \n",
    "#     losses = []\n",
    "#     for value in (hidden):\n",
    "#         dense = modelDense2(superParent, regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS, value)\n",
    "#         dense.compile(optimizer='adam', loss=ignore_noParent_MSE)\n",
    "#         dense.fit(allData, allData, epochs=40,  verbose=0)\n",
    "#         test_hat = dense(allData) #, verbose = 0)\n",
    "#         loss = ignore_noParent_MSE(allData, test_hat)\n",
    "#         losses.append(loss)\n",
    "#         tf.keras.backend.clear_session()\n",
    "#     lossMatrix.append(losses)\n",
    "    \n",
    "# lossMatrix = np.array(lossMatrix)\n",
    "# #run 100 times \n",
    "\n",
    "#To test on testset: \n",
    "N = 40\n",
    "hidden = np.arange(2,24, 1) #range(1,32)\n",
    "lossMatrix = []\n",
    "for i in tqdm(range(N)):\n",
    "    \n",
    "    losses = []\n",
    "    for value in (hidden):\n",
    "        dense = modelDense2(superParent, regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS, value)\n",
    "        dense.compile(optimizer='adam', loss=ignore_noParent_MSE)\n",
    "        dense.fit(beanIntensities, beanIntensities, epochs=40,  verbose=0)\n",
    "        test_hat = dense(validation) #, verbose = 0)\n",
    "        loss = ignore_noParent_MSE(validation, test_hat)\n",
    "        losses.append(loss)\n",
    "        tf.keras.backend.clear_session()\n",
    "    lossMatrix.append(losses)\n",
    "    \n",
    "lossMatrix = np.array(lossMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avgMSE = np.average(lossMatrix, axis = 0)\n",
    "plt.plot(hidden, avgMSE);\n",
    "plt.xlabel(\"Latent Space Size\");\n",
    "plt.ylabel(\"MSE\");\n",
    "plt.title(\"MSE of the AutoEncoder with Respect to the Latent Space Size\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = pd.DataFrame(lossMatrix)\n",
    "lm.to_csv(\"lossmatrix4lisa_soybean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 23)\n"
     ]
    }
   ],
   "source": [
    "temp = pd.read_csv(\"lossmatrix4lisa.csv\").to_numpy()\n",
    "print(temp.shape)\n",
    "avgMSE = np.average(lossMatrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x298edeaed60>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hidden, avgMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_lazy_train(epochs=60, hidden = 32):\n",
    "    ep = epochs\n",
    "    hidden = [hidden,] #range(1,32)\n",
    "    lossMatrix = []\n",
    "    lazy_weights = []\n",
    "    dense = modelDense2(superParent, regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS, num_hidden_units=32)\n",
    "    dense.compile(optimizer='adam', loss=ignore_noParent_MSE)\n",
    "\n",
    "    #for i in tqdm(range(ep)):\n",
    "    for i in range(ep):\n",
    "        dense.fit(beanIntensities, beanIntensities, validation_data=(validation, validation), epochs=1,  verbose=0)\n",
    "        lazy_weights.append(dense.get_weights())\n",
    "        test = dense(validation) #, verbose = 0)\n",
    "        loss = ignore_noParent_MSE(validation, test)\n",
    "        lossMatrix.append(loss)\n",
    "        \n",
    "    lossMatrix = np.array(lossMatrix)\n",
    "    lazy_weights = np.array(lazy_weights)\n",
    "\n",
    "    return lossMatrix, lazy_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://proceedings.mlr.press/v162/rachwan22a/rachwan22a.pdf Winning the Lottery Ticket Ahead of Time:\n",
    "def lazyKernelRegime(w, parent_idx=parent_idx):\n",
    "\n",
    "    firstLayer = []\n",
    "    for i in range(len(w)):\n",
    "        firstLayer.append(w[i][0][parent_idx])\n",
    "\n",
    "    fL = np.array(firstLayer)    \n",
    "    d0 = np.square(fL[1] - fL[0])\n",
    "    kernelChange = []\n",
    "    for i in range(1,len(fL)):\n",
    "        dt = np.square(fL[i] - fL[0])\n",
    "        dt_minus1 = np.square(fL[i-1] - fL[0])   \n",
    "        d = np.abs(dt - dt_minus1)/d0                        #eq 11 from the paper\n",
    "        kernelChange.append(d)\n",
    "    \n",
    "    kernelChange = np.moveaxis(kernelChange, 0, 2)\n",
    "    # plt.plot(kernelChange[0][0]);\n",
    "    # plt.title(\"$|\\Delta W|$ vs Epoch\")\n",
    "    # plt.xlabel(\"Epoch\")\n",
    "    # plt.ylabel(\"$|\\Delta W|$\")\n",
    "\n",
    "    return np.array(  kernelChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distrib(change, t = .05, raw = False): #raw means return the unshaped indicies. \n",
    "    stop = []\n",
    "\n",
    "    for parent in range(len(change)):\n",
    "        for child in range(len(change[0])):\n",
    "            try:\n",
    "                stop.append(np.min(np.argwhere(change[parent][child] < t)))\n",
    "            except ValueError:\n",
    "                stop.append(len(change))\n",
    "                # print(parent, child)\n",
    "                # plt.plot(change[parent][child])\n",
    "                # assert(False)\n",
    "    # print(change.shape)\n",
    "    # assert(False)\n",
    "    \n",
    "    stop = np.array(stop).flatten()\n",
    "    # print(stop.shape)\n",
    "    var = np.std(stop)\n",
    "    # print(var)\n",
    "    # assert(False)\n",
    "    mean = np.average(stop)\n",
    "    top_parents = np.argwhere(stop > mean + 2*var) #get the parents which take more than 2 stds to stop training\n",
    "    top_parent_child = []\n",
    "    for tp in top_parents:\n",
    "        top_parent_child.append(np.unravel_index(tp, shape = (NUM_PARENTS, NUM_TARGETS)))\n",
    "\n",
    "    if raw == False:\n",
    "        plt.hist(stop)\n",
    "        plt.xlabel(\"Epoch where regulator-target-weight began changing by at most \"+ str(t));\n",
    "        plt.ylabel(\"Number of parent-child-weights\");\n",
    "        plt.title(\"Histogram of weight stops\");\n",
    "        print(\"average stop: \", mean);\n",
    "\n",
    "    if raw == True:\n",
    "        return np.array(top_parents)\n",
    "\n",
    "    return np.array(top_parent_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazyKernels(N=100):\n",
    "\n",
    "    candidates = []\n",
    "    final_w = []\n",
    "    for i in tqdm(range(N)):\n",
    "        lm, lazy_weights = do_lazy_train(epochs=80)\n",
    "        change = lazyKernelRegime(lazy_weights)\n",
    "        top_pr = np.squeeze(compute_distrib(change, t = 0.05, raw=True))\n",
    "        candidates.append(top_pr)\n",
    "        final_w.append(lazy_weights[-1])\n",
    "    \n",
    "    final_w = np.array(final_w)\n",
    "    firstLayer = []\n",
    "    for i in range(len(final_w)):\n",
    "        firstLayer.append(np.abs(final_w[i][0][parent_idx]))\n",
    "    fw = np.array(firstLayer)\n",
    "    #print(fw.shape)\n",
    "    fw_avg = np.average(fw, axis = 0)\n",
    "    #print(fw_avg.shape)\n",
    "    \n",
    "    candidates = np.hstack(candidates)\n",
    "    candidates = candidates.reshape(candidates.size)\n",
    "    #print(candidates.shape)\n",
    "\n",
    "    plt.hist(candidates, bins=np.arange(0, NUM_PARENTS*NUM_TARGETS))\n",
    "    plt.title(\"Parent-Child Regulator Histogram\")\n",
    "    plt.xlabel(\"Parent-Child Weight\")\n",
    "    plt.ylabel(\"Num-Times parent-child relationship trained for top 5% of time\")\n",
    "    return candidates, fw_avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [25:02<00:00, 15.02s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "can, mag = lazyKernels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3342,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf, bins = np.histogram(can, np.arange(NUM_PARENTS*NUM_TARGETS))\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 372)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnitudes After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2604"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_PARENTS*NUM_TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "index 2604 is out of bounds for array with size 2604",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Fin Amin\\Desktop\\StemCellResearch\\beanEncoder\\BeanEncoderMain.ipynb Cell 62\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Fin%20Amin/Desktop/StemCellResearch/beanEncoder/BeanEncoderMain.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49munravel_index([NUM_PARENTS\u001b[39m*\u001b[39;49mNUM_TARGETS], shape \u001b[39m=\u001b[39;49m (NUM_PARENTS, NUM_TARGETS))\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36munravel_index\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: index 2604 is out of bounds for array with size 2604"
     ]
    }
   ],
   "source": [
    "#np.unravel_index([NUM_PARENTS*NUM_TARGETS], shape = (NUM_PARENTS, NUM_TARGETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_reg_targets(can, mag):\n",
    "    \n",
    "    pdf, bins = np.histogram(can, np.arange(0, NUM_PARENTS*NUM_TARGETS))\n",
    "    pdf2d = np.zeros(shape = (NUM_PARENTS,NUM_TARGETS))\n",
    "    print(\"num bins\", len(bins))\n",
    "\n",
    "    for i in bins:\n",
    "      idx2d = np.unravel_index(i, shape = (NUM_PARENTS, NUM_TARGETS))\n",
    "      try:\n",
    "        pdf2d[idx2d] = pdf[i]\n",
    "      except IndexError:\n",
    "        print(i, idx2d, len(pdf), len(bins))\n",
    "    \n",
    "\n",
    "    importance = np.multiply(pdf2d, mag)\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num bins 2604\n",
      "2603 (6, 371) 2603 2604\n"
     ]
    }
   ],
   "source": [
    "top = get_top_reg_targets(can, mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 372)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u = plt.imshow(top/np.max(top), cmap = 'inferno', vmin = 0, vmax = 1.0 );\n",
    "plt.colorbar(u ,fraction=0.0086, pad=0.02);\n",
    "plt.title(\"The Most Important Regulator-Target Combinations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[259,  20],\n",
       "       [164,  36],\n",
       "       [225, 241],\n",
       "       ...,\n",
       "       [259, 265],\n",
       "       [131, 270],\n",
       "       [350, 371]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topID = np.array(np.unravel_index(np.argsort(top, axis=None), top.shape))\n",
    "topID = np.flip(topID, axis=1)\n",
    "topID[0] = parent_idx[topID[0]]\n",
    "topID = topID.T\n",
    "topID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topR_T = pd.DataFrame(topID)\n",
    "topR_T.to_csv(\"SOYBEAN_Top_reg_target_decendingOrder_firstColIsRegulator.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.zeros(NUM_PARENTS)\n",
    "for i in range(NUM_PARENTS):\n",
    "    best[i] = np.sum(top[i])\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,NUM_PARENTS, dtype=int)\n",
    "plt.plot(x, best); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.flip(np.argsort(best))\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_idx[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(can).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Petal Len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal = pd.read_excel(data_path_petal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_train = petal[petal[\"Line\"] == \"WT\"]\n",
    "petal_train = petal_train.drop(columns=['Line', 'ID', \"Treatment\"])\n",
    "petal_train.head(12)\n",
    "petal_train = petal_train.groupby(['Plate']).mean()\n",
    "petal_train.head()\n",
    "petal_train = petal_train.to_numpy()\n",
    "print(petal_train.shape)\n",
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(petal_train)\n",
    "petal_train = scaler1.transform(petal_train)\n",
    "mm = MinMaxScaler()\n",
    "mm.fit(petal_train)\n",
    "petal_train = mm.transform(petal_train)\n",
    "petal_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_test = petal[petal[\"Line\"] != \"WT\"]\n",
    "petal_test = petal_test.drop(columns=['Line', 'ID', \"Treatment\"])\n",
    "petal_test = petal_test.groupby(['Plate']).mean()\n",
    "petal_test.head()\n",
    "petal_test = petal_test.to_numpy()\n",
    "print(petal_test.shape)\n",
    "petal_test = scaler1.transform(petal_test)\n",
    "petal_test = mm.transform(petal_test)\n",
    "petal_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1.shape\n",
    "testCandidate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densePredictor = modelDense2(superParent, regulator_gene_matrix, NUM_TARGETS, 6, NUM_TARGETS, 22)\n",
    "densePredictor.compile(optimizer='adam', loss=ignore_noParent_MSE)\n",
    "densePredictor.fit(beanIntensities, beanIntensities,validation_data=(experiment1, experiment1),  epochs=100,  verbose=1)\n",
    "test = densePredictor(testCandidate) #, verbose = 0)\n",
    "loss = ignore_noParent_MSE(testCandidate, test)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgm = superParent\n",
    "time_steps = 6\n",
    "num_kinase_regulators = NUM_TARGETS\n",
    "num_hidden_units = 22\n",
    "\n",
    "inp = Input(shape=(time_steps, num_kinase_regulators))\n",
    "x = DenseEncoderLinear2(rgm, regulator_gene_matrix, NUM_TARGETS, NUM_TARGETS)(inp)\n",
    "enc = denseencoder2(x, inp, num_hidden_units)\n",
    "denseP = tf.keras.Model(inputs=inp, outputs=enc)\n",
    "#set the weights of the encoder to the weights of auto encoder\n",
    "dw = densePredictor.get_weights()\n",
    "enc_w = dw[0:5]\n",
    "denseP.set_weights(enc_w)\n",
    "#add a dense layer  because we are ouputing 1 number\n",
    "l = Dense(32, activation = 'swish', use_bias=True, kernel_regularizer='l1_l2')(denseP.layers[-1].output)\n",
    "l = Dense(1, activation = 'linear', use_bias = True)(l)\n",
    "denseP = tf.keras.Model(denseP.inputs, l)\n",
    "#denseP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = np.concatenate([experiment1, experiment1, experiment1, experiment1])\n",
    "bp.shape\n",
    "#bigexperiment1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = petal_train[0]\n",
    "b = petal_train[1]\n",
    "c = petal_train[2]\n",
    "d = petal_train[3]\n",
    "\n",
    "petal_train1 = np.array([a,a,a,a, b,b,b,b, c,c,c,c, d,d,d,d]) #does this make sense? we are training network to predict .5\n",
    "petal_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseP.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "denseP.fit(experiment1, petal_train, epochs=500, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCandidate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseP(experiment1) #experiment1 is part of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(denseP(testCandidate)) #model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_test #true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseP.evaluate(testCandidate, petal_test) #eval gave 1.3999 before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the test set and the synthetic dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestSet(test_path):\n",
    "    testFiles = []\n",
    "    for np_name in glob(os.path.join(data_path_testSet,'*.np[yz]')):\n",
    "        k = np.load(os.path.join(data_path_testSet,np_name))\n",
    "        testFiles.append(k)\n",
    "#         print(np_name)\n",
    "#         print(k.shape)\n",
    "    return np.array(testFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PKjzdFCMwFg"
   },
   "outputs": [],
   "source": [
    "def read_files(data_path):\n",
    "\n",
    "    #genes_intensities_data_matrix = pd.read_csv(file_path_intensities, index_col = 0)\n",
    "    #print(os.listdir(data_path))\n",
    "    replicate_files = os.listdir(data_path)\n",
    "    #print('replicate files:',replicate_files)\n",
    "    replicates = []\n",
    "    # i = 0\n",
    "    for file in replicate_files:\n",
    "        \n",
    "        try:\n",
    "            #print('file name:',file)\n",
    "            #print('value of i:',i)\n",
    "            genes_intensities_data_matrix = pd.read_csv(os.path.join(data_path , file), index_col = 0, on_bad_lines='skip')\n",
    "            #print('genes_intensities_data_matrix:',  genes_intensities_data_matrix.head())\n",
    "            replicates.append(np.array(genes_intensities_data_matrix.values, dtype = float))\n",
    "            # i+=1\n",
    "        except PermissionError:\n",
    "            print(\"Not a CSV: \", os.path.join(data_path , file))\n",
    "        \n",
    "    genes_intensities_data_matrix = genes_intensities_data_matrix.values\n",
    "    rgm = np.loadtxt(matrix_path)\n",
    "    rep = np.array(replicates).astype(np.float32)\n",
    "    \n",
    "    return rep, rgm.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCwo4LwlO_FF"
   },
   "outputs": [],
   "source": [
    "beanIntensities, regulator_gene_matrix= read_files(data_path_syn)\n",
    "matrix = regulator_gene_matrix\n",
    "replicates = beanIntensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.zeros(shape = (3,6,8))\n",
    "id = np.unravel_index(3*6*8 - 1, shape = d.shape)\n",
    "d[id] = 1\n",
    "plt.imshow(d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCandidate[0][ : , parentIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outSyn.shape)\n",
    "print(testCandidate.shape)\n",
    "syntheticLoss = ignore_noParent_MSE(np.array([testCandidate[0]]), np.array([outSyn[0]]) )\n",
    "syntheticLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(change[0][22])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"change in weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossMatrix)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(change.shape, lossMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.diff(change[0][22])\n",
    "plt.plot(d)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change[0][0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def compute_tresh(change, stop = 0.05):\n",
    "#     diffs = []\n",
    "#     for parent in range(len(change)):\n",
    "#         for child in range(len(change[0])):\n",
    "#             diffs.append(np.diff(change[parent][child]))\n",
    "#     inflection = []\n",
    "\n",
    "\n",
    "#     try:\n",
    "#         for d in diffs:\n",
    "#             print(np.argwhere(np.abs(d) < stop))\n",
    "#             inflection.append(np.min(np.argwhere(np.abs(d) < stop))) #return where the second derivative is first 0. \n",
    "\n",
    "#     except ValueError:\n",
    "#         print(\"Stop value \", stop, \" is too high, trying stop = \", stop + 0.05)\n",
    "#         # s = stop + 0.05\n",
    "#         # return compute_tresh(change, stop = s)\n",
    "        \n",
    "\n",
    "#     return np.average(inflection)\n",
    "        \n",
    "# d = compute_tresh(change)\n",
    "# d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"mse3.npy\", avgMSE) #mse2/3 is with -1 fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.sciencedirect.com/science/article/pii/S0925231220314570?casa_token=lcEJANqO0JwAAAAA:uL3DGUZctPUZz_sPz1K1i2klMtb83TyKnc9CI3_N-uSOaM7VHL8GhM0jCGYfo25NmpDQQ9Cvlw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rshp = Flatten()(looseParent.layers[-1].output)\n",
    "\n",
    "modelTemp = tf.keras.Model(inputs=looseParent.input, outputs = [rshp])\n",
    "modelTemp.summary()\n",
    "type(modelTemp)\n",
    "explainer = shap.DeepExplainer(modelTemp, syntheticDataTrain)\n",
    "#shap.explainers._deep.deep_tf.op_handlers[\"AddV2\"] = shap.explainers._deep.deep_tf.passthrough #this solves the \"shap_ADDV2\" problem but another one will appear\n",
    "#shap.explainers._deep.deep_tf.op_handlers[\"FusedBatchNormV3\"] = shap.explainers._deep.deep_tf.passthrough #this solves the next problem which allows you to run the DeepExplainer.\n",
    "\n",
    "shap_values = explainer.shap_values(testCandidate[0:1])\n",
    "def f(x):\n",
    "    return modelTemp.predict(x)\n",
    "\n",
    "print(f(testCandidate))\n",
    "explainer = shap.KernelExplainer(f , testCandidate[0:1], link=\"logit\") #svm.predict_proba, X_train, link=\"logit\")\n",
    "shap_values = explainer.shap_values(testCandidate[0:1], nsamples=100)\n",
    "def map2layer(x, layer):\n",
    "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
    "    return K.get_session().run(model.layers[layer].input, feed_dict)\n",
    "e = shap.GradientExplainer(\n",
    "    (model.layers[7].input, model.layers[-1].output),\n",
    "    map2layer(X, 7),\n",
    "    local_smoothing=0 # std dev of smoothing noise\n",
    ")\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import json\n",
    "import shap\n",
    "\n",
    "# load pre-trained model and choose two images to explain\n",
    "model = VGG16(weights='imagenet', include_top=True)\n",
    "X,y = shap.datasets.imagenet50()\n",
    "to_explain = X[[39,41]]\n",
    "\n",
    "# load the ImageNet class names\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "fname = shap.datasets.cache(url)\n",
    "with open(fname) as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "# explain how the input to the 7th layer of the model explains the top two classes\n",
    "def map2layer(x, layer):\n",
    "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
    "    return K.get_session().run(model.layers[layer].input, feed_dict)\n",
    "e = shap.GradientExplainer(\n",
    "    (model.layers[7].input, model.layers[-1].output),\n",
    "    map2layer(X, 7),\n",
    "    local_smoothing=0 # std dev of smoothing noise\n",
    ")\n",
    "shap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)\n",
    "\n",
    "# get the names for the classes\n",
    "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "\n",
    "# plot the explanations\n",
    "shap.image_plot(shap_values, to_explain, index_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(enc_dec_Synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = [5,6]\n",
    "u = tf.concat([a,b], axis = 0)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newConnections = superParent - regulator_gene_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(newConnections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nC = []\n",
    "# for i in range(len(newConnections[0])):\n",
    "#     for j in range(len(newConnections[1])):\n",
    "#         if newConnections[i][j] > 0:\n",
    "#             nC.append([i,j])\n",
    "# nC = np.array(nC)\n",
    "# nC = pd.DataFrame(nC)\n",
    "# nC.to_csv(\"new_connections_in_superParents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Code for testing loss function\n",
    "# print(outSyn.shape)\n",
    "# print(testCandidate.shape)\n",
    "# syntheticLoss = ignore_noParent_MSE(np.array([testCandidate[0]]), np.array([outSyn[0]]) )\n",
    "# syntheticLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Auto Encoder\n",
    "Autoencoder has not been trained on synthetic version of experiement 1. We test on the original experiment 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrRuJ_bsrHll"
   },
   "outputs": [],
   "source": [
    "enc_dec_Synthetic.compile(optimizer='adam', loss=ignore_noParent_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAOZEEvRRVU4"
   },
   "outputs": [],
   "source": [
    "# enc_dec_Synthetic.compile(optimizer='adam',loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntheticDataTrain = beanIntensities[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1649273035573,
     "user": {
      "displayName": "Sahil Anish Palarpwar",
      "userId": "17757512684560375750"
     },
     "user_tz": 240
    },
    "id": "EuNDZx5Ov34I",
    "outputId": "74597aa1-c71c-4491-b8c9-4fefed309325"
   },
   "outputs": [],
   "source": [
    "enc_dec_Synthetic.fit(syntheticDataTrain,syntheticDataTrain,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = enc_dec_Synthetic(testCandidate) #, verbose = 0)\n",
    "loss = ignore_noParent_MSE(testCandidate, test)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = enc_dec_Synthetic.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(w[0], cmap = \"hot\", vmin=0,vmax=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBzDmjqJViEw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we do not need to use this function for the testset\n",
    "def getCSVs(data_path_head):\n",
    "    PATH = data_path_head\n",
    "    EXT = \"*.csv\"\n",
    "    all_csv_files = [file\n",
    "                     for path, subdir, files in os.walk(PATH)\n",
    "                     for file in glob(os.path.join(path, EXT))]\n",
    "    actual = []\n",
    "    for p in all_csv_files:\n",
    "        actual.append(pd.read_csv(p, index_col = 0).to_numpy())\n",
    "    return np.array(actual)\n",
    "    \n",
    "experiment1 = getCSVs(data_path_og_exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCandidate = test.numpy().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCandidate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([beanIntensities[0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCandidate[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([beanIntensities[0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outSyn = enc_dec_Synthetic.predict(testCandidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymagn(A, B):\n",
    "    mse = (np.square(A - B)).mean(axis=None)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outSyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntheticLoss = ignore_noParent_MSE(testCandidate, outSyn )\n",
    "syntheticLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(outSyn-testCandidate).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install keras-visualizer\n",
    "#!pip install pydot\n",
    "#data_path_og_exp1 = data_path_testSet \n",
    "# !pip install pydot\n",
    "# !pip install pydotplus\n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = loadTestSet(data_path_testSet)\n",
    "# testCandidate = test.astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPRV0OAMpKPH"
   },
   "outputs": [],
   "source": [
    "enc_dec_Synthetic = model(regulator_gene_matrix, NUM_TARGETS, NUM_TIME_STEPS, NUM_TARGETS) #we can just change the time steps to something higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1649273028683,
     "user": {
      "displayName": "Sahil Anish Palarpwar",
      "userId": "17757512684560375750"
     },
     "user_tz": 240
    },
    "id": "D6aPT5_cpKK0",
    "outputId": "c261d824-0f38-4eee-b139-f03a80f093e1"
   },
   "outputs": [],
   "source": [
    "enc_dec_Synthetic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolated dataset Auto Encoder\n",
    "Once again, we do not train on any version of exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filesV2(data_path):\n",
    "    '''\n",
    "    *Changed*\n",
    "    currently hardcoded for only one file. \n",
    "    change code a bit for reading multiple files.\n",
    "    '''\n",
    "    #genes_intensities_data_matrix = pd.read_csv(file_path_intensities, index_col = 0)\n",
    "    #print(os.listdir(data_path))\n",
    "    replicate_files = os.listdir(data_path)\n",
    "    #print('replicate files:',replicate_files)\n",
    "    replicates = []\n",
    "    # i = 0\n",
    "    for file in replicate_files:\n",
    "        \n",
    "        #print('file name:',file)\n",
    "        #print('value of i:',i)\n",
    "        genes_intensities_data_matrix = pd.read_csv(os.path.join(data_path , file), index_col = 0, on_bad_lines='skip')\n",
    "        #print('genes_intensities_data_matrix:',  genes_intensities_data_matrix.head())\n",
    "        replicates.append(genes_intensities_data_matrix.values)\n",
    "        # i+=1\n",
    "        \n",
    "    genes_intensities_data_matrix = genes_intensities_data_matrix.values\n",
    "    rgm = np.loadtxt(matrix_path)\n",
    "    \n",
    "    return np.asarray(replicates), rgm.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_genes, _ = read_filesV2(data_path_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(interpolated_genes[2]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = []\n",
    "for k in range(len(interpolated_genes)):\n",
    "    #print(k)\n",
    "    if k == 2 or k == 3 or k == 4:\n",
    "        inter.append(np.reshape(interpolated_genes[k], (4,6,NUM_TARGETS)))\n",
    "    else: \n",
    "        inter.append(np.reshape(interpolated_genes[k], (5,6,NUM_TARGETS)))\n",
    "inter = np.vstack(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beanIntensities[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_inter = model(regulator_gene_matrix, NUM_TARGETS, 6, NUM_TARGETS) \n",
    "enc_dec_inter.compile(optimizer='adam', loss=ignore_noParent_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_inter.fit(inter, inter,epochs=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outInter = enc_dec_inter.predict(testCandidate)\n",
    "interpolationLoss = ignore_noParent_MSE(testCandidate, outInter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolationLoss #used to be 3.84 on broke ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outInter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = enc_dec_inter.history\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons between various outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = plt.imshow(np.reshape((np.abs(outSyn)), (24,NUM_TARGETS)), cmap = \"hot\", vmin=0,vmax=1.0 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pd.DataFrame(outSyn[0])\n",
    "u.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pd.DataFrame(testCandidate[0])\n",
    "u.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "u = plt.imshow(np.reshape((np.abs(outSyn-outInter)), (24,NUM_TARGETS)), cmap = \"hot\")#, vmin=0,vmax=1.0 );\n",
    "plt.title(\"Difference Between the Outputs of Both Autoencoders\", fontsize = 40);\n",
    "plt.xlabel(\"Phosphopeptide\", fontsize = 30);\n",
    "plt.ylabel(\"Times Concatenated\", fontsize = 30);\n",
    "plt.colorbar(u ,fraction=0.0046, pad=0.02);\n",
    "#plt.savefig(\"DiffBetweenOut.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "u = plt.imshow(np.reshape(np.abs(outInter-experiment1), (24,NUM_TARGETS)) , cmap = \"hot\") #, vmin=0,vmax=1.0 )\n",
    "plt.title(\"Difference Between the Input and Output of the Autoencoder Trained on Interpolated Data\", fontsize = 40);\n",
    "plt.xlabel(\"Phosphopeptide\", fontsize = 30)\n",
    "plt.ylabel(\"Times Concatenated\", fontsize = 30);\n",
    "plt.colorbar(u ,fraction=0.0046, pad=0.02);\n",
    "#plt.savefig(\"InterDiffImage.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "u = plt.imshow(np.reshape(np.abs(outSyn-experiment1), (24,NUM_TARGETS)), cmap = \"hot\")#, vmin=0,vmax=1.0 )\n",
    "plt.title(\"Difference Between the Input and Output of the Autoencoder Trained on Synthetic Data\", fontsize = 40);\n",
    "plt.xlabel(\"Phosphopeptide\", fontsize = 30);\n",
    "plt.ylabel(\"Times Concatenated\", fontsize = 30);\n",
    "plt.colorbar(u ,fraction=0.0046, pad=0.02);\n",
    "#plt.savefig(\"SynDiffImage.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_idx = parentIndex.numpy()\n",
    "#print(parent_idx)\n",
    "oSyn = (np.reshape((outSyn), (24,NUM_TARGETS)).T)[parent_idx]\n",
    "oSyn = oSyn.T\n",
    "oSyn.shape\n",
    "\n",
    "exp1_col = (np.reshape((experiment1), (24,NUM_TARGETS)).T)[parent_idx]\n",
    "exp1_col = exp1_col.T\n",
    "print(exp1_col.shape)\n",
    "\n",
    "u = plt.imshow(np.abs(oSyn - exp1_col), cmap = 'hot') #TODO use TF loss function instead of difference.\n",
    "ddff = oSyn-exp1_col\n",
    "plt.colorbar(u)\n",
    "plt.title(\"Difference Between the Input and Output of the Autoencoder Trained on Synthetic Data. Only parents.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(oSyn).head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(exp1_col).head(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ddff).head(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"interpolated_v2.npy\", inter) #the interpolated dataset\n",
    "# np.save(\"synthetic_v2.npy\", beanIntensities[1:]) # the synthetic dataset\n",
    "# np.save(\"synOut_v2.npy\", outSyn) #the output of the encoder trained on synthetic data with the input being exp1\n",
    "# np.save(\"interOut_v2.npy\", outInter) #the output of the encoder trained on interpolated data with the input being exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6J5QSynTTgZ+lFOhgOtAG",
   "collapsed_sections": [],
   "name": "cnn-third.ipynb",
   "provenance": [
    {
     "file_id": "1mmRxO5jnBc5CdzxXj8sMtPpG0BQ0ulSs",
     "timestamp": 1648921397876
    },
    {
     "file_id": "10758zFj2UnTnwpQaSFIr5r9MqZWdiMsf",
     "timestamp": 1648674775255
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
